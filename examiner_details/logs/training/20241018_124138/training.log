============================================================

Autoencoder Training Job
Job ID: 236604.hpc2.hpc
Job Name: training
Node(s): n05.hpc
Queue: bix
Submitted by: 25543350
Training Output Directory: /home/25543350/autoencoder1/models/20241018_124138/training_results
Feature Directory: /home/25543350/autoencoder1/features/example_features

============================================================

Starting model training using train_model.py

=== Chains ===

Number of test chains: 2

Number of training chains: 5

Total Chains: 7



=== Dataset Sizes ===

Original dataset size (unbalanced): 771

Number of training residues: 616

Number of validation residues: 155

Total residues: 771




=== Model Architecture ===

Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=180, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Dropout(p=0.01, inplace=False)
    (4): Linear(in_features=128, out_features=96, bias=True)
    (5): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Dropout(p=0.01, inplace=False)
    (8): Linear(in_features=96, out_features=64, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=64, out_features=96, bias=True)
    (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Dropout(p=0.01, inplace=False)
    (4): Linear(in_features=96, out_features=128, bias=True)
    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Dropout(p=0.01, inplace=False)
    (8): Linear(in_features=128, out_features=180, bias=True)
  )
)


=== Model Parameters ===

input_dim: 180

Layers: [128, 96]

Latent Dimension: 64

Dropout Rate: 0.01

Batch Size: 64

Learning Rate: 0.001

Epochs: 3

Device: cpu

Balanced Sampling: False

Seed: 42

Negative Slope: 0.01

Save Validation Features: True

Train-Validation Split: 0.8



=== Optimizer ===

Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)



Starting training loop...

Number of training residues: 616
Number of validation residues: 155

Epoch 1/3

Training Loss: 1.095396
Validation Loss: 0.979799

Epoch 2/3

Training Loss: 0.959309
Validation Loss: 0.946770

Epoch 3/3

Training Loss: 0.886479
Validation Loss: 0.898108

Training loop completed.

Model saved to /home/25543350/autoencoder1/models/20241018_124138/training_results/trained_model.pth

Generating plots and reports...

UMAP Trustworthiness Score (n_neighbors=16, min_dist=0.1): 0.84

Saved features for 5 chains
Final Validation MSE: 0.898108

Training process completed successfully.

============================================================

Training completed, starting test set inference using inference.py

/new-home/25543350/autoencoder1/autoencoder/inference.py:159: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.model_path, map_location=self.device)
=== Chains ===

Number of chains processed: 2

=== Dataset Sizes ===

Number of residues processed: 309


=== Model Architecture ===

Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=180, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Dropout(p=0.01, inplace=False)
    (4): Linear(in_features=128, out_features=96, bias=True)
    (5): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Dropout(p=0.01, inplace=False)
    (8): Linear(in_features=96, out_features=64, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=64, out_features=96, bias=True)
    (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Dropout(p=0.01, inplace=False)
    (4): Linear(in_features=96, out_features=128, bias=True)
    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Dropout(p=0.01, inplace=False)
    (8): Linear(in_features=128, out_features=180, bias=True)
  )
)


Starting forward pass...

Inference completed.

Generating plots and reports...


PCA Explained Variance Ratios (first 2 components): [0.16672824 0.06870257]
PCA Cumulative Explained Variance Ratio (first 2 components): 0.24

UMAP Trustworthiness Score (n_neighbors=16, min_dist=0.1): 0.75

UMAP Trustworthiness Score (n_neighbors=16, min_dist=0.1): 0.86

Saved features for 2 chains
Forward pass processing completed successfully.

============================================================

Inference completed, starting SeqPredNN inference on test set using predict.py

/home/25543350/SeqPredNN/SeqPredNN/predict.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  parameters = torch.load(parameter_path, map_location=device) # Added map_location=device explicitly
Chain 1/2
1YTBA - Predicted sequence:
GGEVPKVLKVEATVDTGKPVDLEEIAEELPNTTFDPEVSDAVLASVDDPPSTALLLESGSAIVTGATSEEELEKVARAVAELLKELGLDAKLVNLKILEVSVSSDLGKPVDLEELAEKNEEKGSFDPDKDPKLLVLPKDPDVTVLITPSGTVTVSGATSEETVLRVVKALLDLLEAFSLR
1YTBA - Original sequence:
SGIVPTLQNIVATVTLGCRLDLKTVALHARNAEYNPKRFAAVIMRIREPKTTALIFASGKMVVTGAKSEDDSKLASRKYARIIQKIGFAAKFTDFKIQNIVGSCDVKFPIRLEGLAFSHGTFSSYEPELFPGLIYRMVKPKIVLLIFVSGKIVLTGAKQREEIYQAFEAIYPVLSEFRKM

Chain 2/2
2CDSA - Predicted sequence:
EVPTLEELLRLLRKNGLDGINGIPPGLLVAAAKNTFGGDPDAKEELPDGARLLGAFNISPEELVDDGNVPNLSFPANRDAEELTSSDPEPAVRLALLIIAKEEGLSLSPEAKNHVKGKDVEELVKGADT
2CDSA - Original sequence:
KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL

============================================================

Starting SeqPredNN inference on reconstructed test set using predict.py

/home/25543350/SeqPredNN/SeqPredNN/predict.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  parameters = torch.load(parameter_path, map_location=device) # Added map_location=device explicitly
Chain 1/2
1YTBA - Predicted sequence:
GGGGGGGGGGGPGAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGGGGGGGGLGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
1YTBA - Original sequence:
SGIVPTLQNIVATVTLGCRLDLKTVALHARNAEYNPKRFAAVIMRIREPKTTALIFASGKMVVTGAKSEDDSKLASRKYARIIQKIGFAAKFTDFKIQNIVGSCDVKFPIRLEGLAFSHGTFSSYEPELFPGLIYRMVKPKIVLLIFVSGKIVLTGAKQREEIYQAFEAIYPVLSEFRKM

Chain 2/2
2CDSA - Predicted sequence:
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGPGGGGGGGGGGGGGGGGG
2CDSA - Original sequence:
KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL


============================================================

Training Completed
Results:
  Training Output Directory: /home/25543350/autoencoder1/models/20241018_124138/training_results
  Inference Output Directory: /home/25543350/autoencoder1/models/20241018_124138/test_inference_results
  SeqPredNN Inference (Original Features): /home/25543350/autoencoder1/models/20241018_124138/original_seqprednn_results
  SeqPredNN Inference (Recontructed Features): /home/25543350/autoencoder1/models/20241018_124138/reconstructed_seqprednn_results
  Process started at: Fri Oct 18 12:41:38 SAST 2024
  Process ended at: Fri Oct 18 12:44:29 SAST 2024
